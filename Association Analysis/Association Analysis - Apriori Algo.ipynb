{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        data = [[int(x) for x in line.rstrip().split()] for line in content]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 5],\n",
       " [2, 4],\n",
       " [2, 3],\n",
       " [1, 2, 4],\n",
       " [1, 3],\n",
       " [2, 3],\n",
       " [1, 3],\n",
       " [1, 2, 3, 5],\n",
       " [1, 2, 3]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset = load_dataset('small_retail.txt')\n",
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSet1(dataset):\n",
    "    c1 = []\n",
    "    allItems = set()\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            allItems.add(item)\n",
    "    for item in sorted(allItems):\n",
    "        c1.append(frozenset([item]))\n",
    "    return c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_candidates(candidate, dataset, min_sup):\n",
    "    retlist = []\n",
    "    support_data = {cand:0 for cand in candidate}\n",
    "    for transaction in dataset:\n",
    "        for candidate in support_data:\n",
    "            if candidate.issubset(transaction):\n",
    "                support_data[candidate] += 1\n",
    "    for candidate in support_data:\n",
    "        if support_data[candidate] >= min_sup:\n",
    "            retlist.append(candidate)\n",
    "    return retlist, support_data\n",
    "#print(filter_candidates(createSet1(small_dataset), small_dataset, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def generateNextItemsets(freq_sets):\n",
    "    retlist = []\n",
    "    for i in range(len(freq_sets)):\n",
    "        for j in range(i, len(freq_sets)):\n",
    "            if i != j:\n",
    "                new_set = freq_sets[i] & freq_sets[j]\n",
    "                if len(new_set) == len(freq_sets[i]) - 1:\n",
    "                    new_set = freq_sets[i] | freq_sets[j]\n",
    "                if valid_candidateSet(new_set, freq_sets):\n",
    "                    retlist.append(new_set)\n",
    "    return retlist\n",
    "\n",
    "# Returns True if all subsets of new_set are candidate sets (meet minsup), returns False otherwise\n",
    "def valid_candidateSet(new_set, old_sets):\n",
    "    if len(new_set) == 0:\n",
    "        return False\n",
    "    subsets = list(combinations(new_set, len(new_set)-1))\n",
    "    old_set_list = [sorted(old_cand) for old_cand in old_sets]\n",
    "    for subset in subsets:\n",
    "        if sorted(subset) not in old_set_list:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#freq, di = filter_candidates(createSet1(small_dataset), small_dataset, 6)\n",
    "#print(freq)\n",
    "#new_list = generateNextItemsets(freq)\n",
    "#print(new_list)\n",
    "#print(valid_candidateSet(frozenset([1,2,3]), [frozenset([1,2]), frozenset([2,3]), frozenset([1,3])]))\n",
    "#print(list(frozenset([1,2])) == [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aprioriFreqItemsets(dataset, minsup):\n",
    "    total_itemset = []\n",
    "    total_support_data = {}\n",
    "    retlist, support_data = filter_candidates(createSet1(dataset), dataset, minsup)\n",
    "    while retlist:\n",
    "        for i in retlist: total_itemset.append(i)\n",
    "        total_support_data.update(support_data)\n",
    "        newCandidates = generateNextItemsets(retlist)\n",
    "        retlist, support_data = filter_candidates(newCandidates, dataset, minsup)\n",
    "    return total_itemset, total_support_data\n",
    "#i, j = aprioriFreqItemsets(small_dataset, 4)\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sup\tFreq Itemset \n",
      "0.1\t[31]\n",
      "0.23\t[32]\n",
      "0.11\t[36]\n",
      "0.26\t[38]\n",
      "0.6\t[39]\n",
      "0.31\t[41]\n",
      "0.47\t[48]\n",
      "0.11\t[60]\n",
      "0.11\t[65]\n",
      "0.11\t[89]\n",
      "0.14\t[32, 39]\n",
      "0.12\t[32, 48]\n",
      "0.17\t[38, 39]\n",
      "0.11\t[38, 41]\n",
      "0.13\t[38, 48]\n",
      "0.23\t[39, 41]\n",
      "0.33\t[39, 48]\n",
      "0.18\t[41, 48]\n",
      "0.14\t[39, 41, 48]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('large_retail.txt')\n",
    "totalTransactions = len(data)\n",
    "freqItemsets, support_data = aprioriFreqItemsets(data, 300)\n",
    "tempset = [sorted(i) for i in freqItemsets]\n",
    "\n",
    "sorted_freqItemsets = sorted(tempset, key=lambda x: (len(list(x)),list(x)))\n",
    "\n",
    "output = \"Sup\\tFreq Itemset \\n\"\n",
    "for itemSet in sorted_freqItemsets:\n",
    "    support_fraction = support_data[frozenset(itemSet)] / totalTransactions\n",
    "    output += str(round(support_fraction, 2)) + \"\\t\" + str(itemSet) + \"\\n\"\n",
    "\n",
    "file = open('apriori_itemsets.txt','w') \n",
    "file.write(output)\n",
    "file.close()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sup\tFreq Itemset \n",
      "0.1\t[31]\n",
      "0.23\t[32]\n",
      "0.11\t[36]\n",
      "0.26\t[38]\n",
      "0.6\t[39]\n",
      "0.31\t[41]\n",
      "0.47\t[48]\n",
      "0.11\t[60]\n",
      "0.11\t[65]\n",
      "0.11\t[89]\n",
      "0.14\t[32, 39]\n",
      "0.12\t[32, 48]\n",
      "0.17\t[38, 39]\n",
      "0.11\t[38, 41]\n",
      "0.13\t[38, 48]\n",
      "0.23\t[39, 41]\n",
      "0.33\t[39, 48]\n",
      "0.18\t[41, 48]\n",
      "0.14\t[39, 41, 48]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = \"Sup\\tFreq Itemset \\n\"\n",
    "for i in range(len(sorted_freqItemsets)):\n",
    "    for j in range(i, len(sorted_freqItemsets)):\n",
    "        if set(sorted_freqItemsets[j]).issuperset(sorted_freqItemsets[i]) and support_data[frozenset(sorted_freqItemsets[i])] <= support_data[frozenset(sorted_freqItemsets[j])]:\n",
    "            support_fraction = support_data[frozenset(sorted_freqItemsets[i])] / totalTransactions\n",
    "            output += str(round(support_fraction, 2)) + \"\\t\" + str(sorted_freqItemsets[i]) + \"\\n\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
