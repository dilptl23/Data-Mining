{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataPoint:\n",
    "    def __str__(self):\n",
    "        return \"< \" + str(self.label) + \": \" + str(self.features) + \" >\"\n",
    "    def __init__(self, label, features):\n",
    "        self.label = label # the classification label of this data point\n",
    "        self.features = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            record = np.fromstring(line, sep=\",\")\n",
    "            label = record[-1]\n",
    "            record = record[:-1]\n",
    "            data.append(DataPoint(label, record))\n",
    "    return data\n",
    "\n",
    "def PrintDataSet(data):\n",
    "    for d in data:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    is_leaf = True          \n",
    "    feature_idx = None      \n",
    "    thresh_val = None       \n",
    "    prediction = None       \n",
    "    left_child = None       \n",
    "    right_child = None      \n",
    "    \n",
    "    def printTree(self):    # for debugging purposes\n",
    "        if self.is_leaf:\n",
    "            print ('Leaf Node:      predicts ' + str(self.prediction))\n",
    "        else:\n",
    "            print ('Internal Node:  splits on feature ' \n",
    "                   + str(self.feature_idx) + ' with threshold ' + str(self.thresh_val))\n",
    "            self.left_child.printTree()\n",
    "            self.right_child.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(tree_root, data_point):\n",
    "    # is_leaf is when you check prediction\n",
    "    # go left if less and right if greater than or equal to\n",
    "    node = tree_root\n",
    "    while(node.is_leaf is False):\n",
    "        if data_point.features[node.feature_idx] < node.thresh_val:\n",
    "            node = node.left_child\n",
    "        else:\n",
    "            node = node.right_child\n",
    "    #Is leaf\n",
    "    return node.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(data, feature_idx, threshold):\n",
    "    left_split = []\n",
    "    right_split = []\n",
    "    for d in data:\n",
    "        #print(\"Threshold: \" + str(threshold))\n",
    "        #print(\"Feature Value: \" + str(d.features[feature_idx]))\n",
    "        \n",
    "        if d.features[feature_idx] < threshold:\n",
    "            left_split.append(d)\n",
    "        else:\n",
    "            right_split.append(d)\n",
    "    return (left_split, right_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(data):\n",
    "    entropy = 0.0\n",
    "    # find the number of 0's and the number of 1's then calculate\n",
    "    signs = 0 #1\n",
    "    noSigns = 0 #0\n",
    "    for d in data:\n",
    "        if d.label == 1:\n",
    "            signs += 1\n",
    "        else:\n",
    "            noSigns += 1\n",
    "    totalCount = signs + noSigns\n",
    "\n",
    "    signPerc = signs/totalCount\n",
    "    if signPerc == 0:\n",
    "        signPerc = 1\n",
    "    noSignPerc = noSigns / totalCount\n",
    "    if noSignPerc == 0:\n",
    "        noSignPerc = 1\n",
    "    entropy = -(signs/totalCount)*log(signPerc,2.0) - (noSigns/totalCount)*log(noSignPerc, 2.0)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_best_threshold(data, feature_idx):\n",
    "    best_info_gain = 0.0\n",
    "    best_thresh = None\n",
    "\n",
    "    #continuous variable - finding best split\n",
    "    # create a dict with {feature idx, label}, then sort dict and go forward with the algorithm\n",
    "    \n",
    "    #use split_data feature to get tuples and split, still need to get the value to split on\n",
    "    # create list of feature_idx and sort, to make it more efficicent create a dict with label as value\n",
    "    feature_list = []\n",
    "    numOfYes = 0\n",
    "    for d in data:\n",
    "        feature_list.append(d.features[feature_idx])\n",
    "        if d.label == 1:\n",
    "            numOfYes += 1\n",
    "    feature_list.sort()\n",
    "    \n",
    "    data_sorted = data\n",
    "    data_sorted.sort(key=lambda x: x.features[feature_idx])\n",
    "    \n",
    "    #calculate gini of Parent\n",
    "    entropy_parent = calc_entropy(data)\n",
    "    \n",
    "    for i in range(1, len(data_sorted)):\n",
    "        #need to find correct i and i+1, where label changes\n",
    "        if data_sorted[i].label == data_sorted[i-1].label and i != 1:\n",
    "            continue\n",
    "        if (feature_list[i] == feature_list[i-1]) and feature_list[i] == min(feature_list):\n",
    "            continue\n",
    "            \n",
    "        # Calculate Split Value\n",
    "        split_value = (feature_list[i]+feature_list[i-1]) / 2.0\n",
    "        \n",
    "        # Split Dataset between split_value\n",
    "        left, right = split_dataset(data, feature_idx, split_value)\n",
    "        \n",
    "        # Calc Entropy of both left and right sides\n",
    "        entropy_left = calc_entropy(left)\n",
    "        entropy_right = calc_entropy(right)\n",
    "\n",
    "        \n",
    "        #calculate entropy of split (weighted average)\n",
    "        entropy_split = (len(left)/len(data))*entropy_left + (len(right)/len(data))*entropy_right\n",
    "        \n",
    "        #calcualate gain: entropy-parent - entropy-split\n",
    "        gain = entropy_parent - entropy_split\n",
    "        \n",
    "        if gain > best_info_gain:\n",
    "            best_info_gain = gain\n",
    "            best_thresh = split_value\n",
    "        \n",
    "    return (best_info_gain, best_thresh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_best_split(data):\n",
    "    if len(data) < 2:\n",
    "        return (None, None)\n",
    "    best_feature = None\n",
    "\n",
    "    # must loop through len(feature_idx-1) and return the feature_idx and threshold of the feature that returns the best_info_gain\n",
    "    best_info_gain = 0\n",
    "    best_threshold = 0\n",
    "    for i in range(0,len(data[0].features)):\n",
    "        gain, thresh = calc_best_threshold(data, i)\n",
    "        if gain >= best_info_gain:\n",
    "            best_feature = i\n",
    "            best_info_gain = gain\n",
    "            best_threshold = thresh\n",
    "            \n",
    "        \n",
    "    return (best_feature, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createLeafNode(data):\n",
    "\n",
    "    # Loop through data and count number of signs vs no-signs for class label. Prediction is 0 or 1 dependent on which occurs most\n",
    "    signs = 0 #1\n",
    "    no_signs = 0 #0\n",
    "    for d in data:\n",
    "        if d.label == 1:\n",
    "            signs += 1\n",
    "        else:\n",
    "            no_signs += 1\n",
    "   \n",
    "    tree = TreeNode()\n",
    "    tree.is_leaf = True\n",
    "    if signs > no_signs:\n",
    "        tree.prediction = 1\n",
    "    else:\n",
    "        tree.prediction = 0\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDecisionTree(data, max_levels):\n",
    "    # if max_level is 1, createLeafNode\n",
    "    tree = TreeNode()\n",
    "    tree.is_leaf = False\n",
    "    if max_levels == 1:\n",
    "        return createLeafNode(data)\n",
    "    \n",
    "    # find what to split on\n",
    "    feature, thresh = identify_best_split(data)\n",
    "    \n",
    "    # if data only has one datapoint in it\n",
    "    if feature is None or thresh is None:\n",
    "        return createLeafNode(data)\n",
    "    left_split, right_split = split_dataset(data, feature, thresh)\n",
    "    tree.feature_idx = feature\n",
    "    tree.thresh_val = thresh\n",
    "    tree.left_child = createDecisionTree(left_split, max_levels-1)\n",
    "    tree.right_child = createDecisionTree(right_split, max_levels-1)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "#dat = get_data(\"test.txt\")\n",
    "#tr = createDecisionTree(dat, 2)\n",
    "#tr.printTree()\n",
    "\n",
    "# Test\n",
    "#dat = get_data(\"test.txt\")\n",
    "#print(str(identify_best_split(dat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcAccuracy(tree_root, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for d in data:\n",
    "        pred = make_prediction(tree_root, d)\n",
    "        if pred == d.label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 920\n",
      "Test set size    : 231\n",
      "Time taken: 13.38956880569458\n",
      "The accuracy on the test set is  68.3982683982684\n",
      "Training set size: 921\n",
      "Test set size    : 230\n",
      "Time taken: 18.114651918411255\n",
      "The accuracy on the test set is  65.21739130434783\n",
      "Training set size: 921\n",
      "Test set size    : 230\n",
      "Time taken: 14.83719515800476\n",
      "The accuracy on the test set is  65.65217391304347\n",
      "Training set size: 921\n",
      "Test set size    : 230\n",
      "Time taken: 16.201844930648804\n",
      "The accuracy on the test set is  59.56521739130435\n",
      "Training set size: 921\n",
      "Test set size    : 230\n",
      "Time taken: 14.071578979492188\n",
      "The accuracy on the test set is  58.69565217391305\n",
      "\n",
      "The average accuracy is 63.50574063617541\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def x_fold(data, fold):\n",
    "    return [data[i::fold] for i in range(fold)]\n",
    "\n",
    "average = 0\n",
    "d = get_data(\"messidor_features.txt\")\n",
    "fold = x_fold(d, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    test_set = fold[i]\n",
    "    train_set = []\n",
    "    for j in range(5):\n",
    "        if j == i:\n",
    "            continue\n",
    "        train_set += fold[j]\n",
    "    # partition data into train_set and test_set\n",
    "    #train_set = d[int(len(d)/5)*i:(int(len(d)/5)*4)]\n",
    "    #test_set = d[(int(len(d)/5)*(4-i)  :  (int(len(d)/5)*(5-i)]\n",
    "\n",
    "    print ('Training set size:', len(train_set))\n",
    "    print ('Test set size    :', len(test_set))\n",
    "\n",
    "    # create the decision tree\n",
    "    start = time.time()\n",
    "    tree = createDecisionTree(train_set, 10)\n",
    "    end = time.time()\n",
    "    print ('Time taken:', end - start)\n",
    "\n",
    "    # calculate the accuracy of the tree\n",
    "    accuracy = calcAccuracy(tree, test_set)\n",
    "    print ('The accuracy on the test set is ', str(accuracy * 100.0))\n",
    "    average += accuracy\n",
    "    #t.printTree()\n",
    "\n",
    "print(\"\\nThe average accuracy is \" +str(average/5*100))\n",
    "                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
